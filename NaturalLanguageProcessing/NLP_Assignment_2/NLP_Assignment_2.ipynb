{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import pylab as pl \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      person_id  gender    generation occupation\n",
      "0             0    male   Millennials     sports\n",
      "1             1    male   Millennials     sports\n",
      "2             2  female  Generation X  performer\n",
      "3             3    male   Millennials     sports\n",
      "4             4    male  Generation X     sports\n",
      "...         ...     ...           ...        ...\n",
      "4668       4668    male   Millennials     sports\n",
      "4669       4669    male   Millennials    creator\n",
      "4670       4670    male       Boomers   politics\n",
      "4671       4671  female       Boomers     sports\n",
      "4672       4672    male  Generation X   politics\n",
      "\n",
      "[4673 rows x 4 columns]\n",
      "     person_id  gender    generation occupation\n",
      "0         4673    male   Millennials     sports\n",
      "1         4674    male  Generation X     sports\n",
      "2         4675    male   Millennials    creator\n",
      "3         4676    male  Generation X  performer\n",
      "4         4677    male  Generation X    creator\n",
      "..         ...     ...           ...        ...\n",
      "515       5188    male   Millennials     sports\n",
      "516       5189    male   Millennials     sports\n",
      "517       5190    male   Millennials     sports\n",
      "518       5191  female       Boomers    creator\n",
      "519       5192    male  Generation X     sports\n",
      "\n",
      "[520 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "labels_train = pd.read_csv(os.path.join(data_path, 'labels_train.csv'), low_memory=False)\n",
    "labels_test = pd.read_csv(os.path.join(data_path, 'labels_test.csv'), low_memory=False)\n",
    "print(labels_train)\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = pd.read_csv(os.path.join(data_path, 'tweets_train.csv'), low_memory=False)\n",
    "tweets_test = pd.read_csv(os.path.join(data_path, 'tweets_test.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        person_id                                              tweet\n",
      "0               0                     Legend https://t.co/cgkeYFI92H\n",
      "1               0  @NHLFlames @bigern10 @calstampeders cannot wai...\n",
      "2               0  RT @Fan960Wills: Help @BBBSCalgary by texting ...\n",
      "3               0  @RMHSouthernAB @NHLFlames thank you Derek. Ver...\n",
      "4               0  RT @RMHSouthernAB: Inspired by his @NHLFlames ...\n",
      "...           ...                                                ...\n",
      "2351794      4672                                @MarioAsselin merci\n",
      "2351795      4672  @MarioAsselin @ramezayoub est ce possible d'av...\n",
      "2351796      4672  @Casup007 Allo Carole as tu un parapluie en pl...\n",
      "2351797      4672  @MarioAsselin @ramezayoub: Bonjour M Asselin d...\n",
      "2351798      4672  Bon lundi à tous je commence par un tweet ce m...\n",
      "\n",
      "[2351799 rows x 2 columns]\n",
      "        person_id                                              tweet\n",
      "0            4673  So proud #RollTide #VictoryWednesday #ThankYou...\n",
      "1            4673        Thanks @jaxdotcom...https://t.co/puQtN4fR2k\n",
      "2            4673  RT @Jaguars: Our players visited NAS JAX to se...\n",
      "3            4673                     #Funny https://t.co/jpPzKyqA2o\n",
      "4            4673           So real ....!!!! https://t.co/GQD8Pe8rPw\n",
      "...           ...                                                ...\n",
      "260144       5192  The two things that take zero ability , attitu...\n",
      "260145       5192  Great recruiting weekend followed by a powerfu...\n",
      "260146       5192  Want to win the Ted Hendricks award for best D...\n",
      "260147       5192       Just got better as a staff today ! # MA=td's\n",
      "260148       5192  Flying down tonight , excited to get back to w...\n",
      "\n",
      "[260149 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweets_train)\n",
    "print(tweets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Legend https://t.co/cgkeYFI92H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@NHLFlames @bigern10 @calstampeders cannot wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @Fan960Wills: Help @BBBSCalgary by texting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@RMHSouthernAB @NHLFlames thank you Derek. Ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @RMHSouthernAB: Inspired by his @NHLFlames ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351794</th>\n",
       "      <td>4672</td>\n",
       "      <td>@MarioAsselin merci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351795</th>\n",
       "      <td>4672</td>\n",
       "      <td>@MarioAsselin @ramezayoub est ce possible d'av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351796</th>\n",
       "      <td>4672</td>\n",
       "      <td>@Casup007 Allo Carole as tu un parapluie en pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351797</th>\n",
       "      <td>4672</td>\n",
       "      <td>@MarioAsselin @ramezayoub: Bonjour M Asselin d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351798</th>\n",
       "      <td>4672</td>\n",
       "      <td>Bon lundi à tous je commence par un tweet ce m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        person_id                                              tweet\n",
       "0               0                     Legend https://t.co/cgkeYFI92H\n",
       "1               0  @NHLFlames @bigern10 @calstampeders cannot wai...\n",
       "2               0  RT @Fan960Wills: Help @BBBSCalgary by texting ...\n",
       "3               0  @RMHSouthernAB @NHLFlames thank you Derek. Ver...\n",
       "4               0  RT @RMHSouthernAB: Inspired by his @NHLFlames ...\n",
       "...           ...                                                ...\n",
       "2351794      4672                                @MarioAsselin merci\n",
       "2351795      4672  @MarioAsselin @ramezayoub est ce possible d'av...\n",
       "2351796      4672  @Casup007 Allo Carole as tu un parapluie en pl...\n",
       "2351797      4672  @MarioAsselin @ramezayoub: Bonjour M Asselin d...\n",
       "2351798      4672  Bon lundi à tous je commence par un tweet ce m...\n",
       "\n",
       "[2351799 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351799"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id    0\n",
       "tweet        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Säubern der Tweets\n",
    "stemmer = SnowballStemmer('english')\n",
    "stopwords_E = stopwords.words('english')\n",
    "\n",
    "def cleaning_tweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    #tweet = re.sub('@[^\\s]+', '', tweet) # entfernt usernames\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # entfernt #hashtag\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', tweet) # entfernt URL\n",
    "    tweet_token = word_tokenize(tweet)\n",
    "    stemmedword = [stemmer.stem(w) for w in tweet_token] \n",
    "    no_stopword = [w for w in stemmedword if w.isalpha() and w not in stopwords_E ]   \n",
    "    words = [w for w in no_stopword if len(w) > 1]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "0       Legend https://t.co/cgkeYFI92H @NHLFlames @big...\n",
       "1       RT @MisterRoast98: It's amazing what a simple ...\n",
       "10      RT @ARNelson7: Had a great time time in Richmo...\n",
       "100     Very sad to hear of Paul Allen’s passing. His ...\n",
       "1000    Thanks for leaving the shanks out 😂 https://t....\n",
       "                              ...                        \n",
       "995     Kæru konur, leggjum niður launuð og ólaunuð st...\n",
       "996     RT @mendy_bernard: Une pensée pour toutes les ...\n",
       "997     Fight night 4 years ago. Good stuff. I miss it...\n",
       "998     RT @PWEverestRugby: Here is the link to my #Ev...\n",
       "999     Who else is seeing @thegreatwall this weekend?...\n",
       "Name: tweet, Length: 4673, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laden und säubern X_train\n",
    "grouped_persons = tweets_train.groupby('person_id')\n",
    "grouped_tweets = grouped_persons['tweet'].agg(lambda column: \" \".join(column))\n",
    "grouped_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets_data = grouped_tweets.apply(lambda row : cleaning_tweet(row)) # ca. 10 minuten wartezeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "0       [legend, nhlflame, calstamped, wait, see, foot...\n",
       "1       [rt, amaz, simpl, group, chat, veri, import, y...\n",
       "10      [rt, great, time, time, richmond, weekend, rea...\n",
       "100     [veri, sad, hear, paul, allen, pass, passion, ...\n",
       "1000    [thank, leav, shank, hbd, man, gis, kiss, carl...\n",
       "                              ...                        \n",
       "995     [kæru, konur, leggjum, niður, launuð, og, ólau...\n",
       "996     [rt, une, pensé, pour, tout, les, personn, qui...\n",
       "997     [fight, night, year, ago, good, stuff, miss, r...\n",
       "998     [rt, pweverestrugbi, link, everestrugbi, justg...\n",
       "999     [els, see, thegreatwal, weekend, excit, watch,...\n",
       "Name: tweet, Length: 4673, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = cleaned_tweets_data.reset_index()\n",
    "cleaned_tweets = cleaned_tweets.drop(columns=['person_id']) \n",
    "#cleaned_tweets = cleaned_tweets.join(labels_train['person_id']) # neu frisch hinzufügen person_id\n",
    "#cleaned_tweets = cleaned_tweets[['person_id','tweet']] # neu column anordnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       legend nhlflame calstamped wait see footag woo...\n",
      "1       rt amaz simpl group chat veri import youth hea...\n",
      "2       rt great time time richmond weekend readingfig...\n",
      "3       veri sad hear paul allen pass passion invent p...\n",
      "4       thank leav shank hbd man gis kiss carlo ricki ...\n",
      "                              ...                        \n",
      "4668    kæru konur leggjum niður launuð og ólaunuð stö...\n",
      "4669    rt une pensé pour tout les personn qui nous on...\n",
      "4670    fight night year ago good stuff miss rt ufc go...\n",
      "4671    rt pweverestrugbi link everestrugbi justgiv pa...\n",
      "4672    els see thegreatwal weekend excit watch matt d...\n",
      "Name: tweet, Length: 4673, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = cleaned_tweets\n",
    "X_train = cleaned_tweets['tweet']\n",
    "X_train = X_train.apply(lambda row : ' '.join(row)) \n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "4673    So proud #RollTide #VictoryWednesday #ThankYou...\n",
       "4674    RT @LSUFBrecruiting: #NFLSU: Week 7 Top Perfor...\n",
       "4675    Remember that the one time Trump owned a profe...\n",
       "4676    :) :) https://t.co/XTmHQagQLI Doston miliye me...\n",
       "4677    RT @shinnox: Every #mk champions breakfast of ...\n",
       "                              ...                        \n",
       "5188    Any 2nd Rows interested in coming to Hong Kong...\n",
       "5189    @nojokemoke Yes Sr!!!! Let’s get it @bschoon86...\n",
       "5190    @HildaEsq @EMorrisonSmith @RiseSanDiego @Karee...\n",
       "5191    ‘Divorce’ Renewed for Season 3 at HBO With New...\n",
       "5192    RT @DurstJarmarquis: It’s truly a blessing to ...\n",
       "Name: tweet, Length: 520, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laden und säubern X_test\n",
    "grouped_persons_test = tweets_test.groupby('person_id')\n",
    "grouped_tweets_test  = grouped_persons_test['tweet'].agg(lambda column: \" \".join(column))\n",
    "grouped_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tweets_test_data =  grouped_tweets_test.apply(lambda row : cleaning_tweet(row)) # ca. 2 minuten wartezeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id\n",
       "4673    [proud, rolltid, victorywednesday, thankyouala...\n",
       "4674    [rt, lsufbrecruit, nflsu, week, top, perform, ...\n",
       "4675    [rememb, one, time, trump, profession, sport, ...\n",
       "4676    [doston, miliy, mere, nay, jodidaar, se, br, h...\n",
       "4677    [rt, shinnox, everi, mk, champion, breakfast, ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tweets_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[proud, rolltid, victorywednesday, thankyouala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[rt, lsufbrecruit, nflsu, week, top, perform, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rememb, one, time, trump, profession, sport, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doston, miliy, mere, nay, jodidaar, se, br, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rt, shinnox, everi, mk, champion, breakfast, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>[ani, row, interest, come, hong, kong, play, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>[nojokemok, yes, sr, let, get, great, wish, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>[hildaesq, emorrisonsmith, risesandiego, wish,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[divorc, renew, season, hbo, new, showrunn, va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>[rt, durstjarmarqui, truli, bless, onli, part,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "0    [proud, rolltid, victorywednesday, thankyouala...\n",
       "1    [rt, lsufbrecruit, nflsu, week, top, perform, ...\n",
       "2    [rememb, one, time, trump, profession, sport, ...\n",
       "3    [doston, miliy, mere, nay, jodidaar, se, br, h...\n",
       "4    [rt, shinnox, everi, mk, champion, breakfast, ...\n",
       "..                                                 ...\n",
       "515  [ani, row, interest, come, hong, kong, play, m...\n",
       "516  [nojokemok, yes, sr, let, get, great, wish, co...\n",
       "517  [hildaesq, emorrisonsmith, risesandiego, wish,...\n",
       "518  [divorc, renew, season, hbo, new, showrunn, va...\n",
       "519  [rt, durstjarmarqui, truli, bless, onli, part,...\n",
       "\n",
       "[520 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tweets_test = grouped_tweets_test_data.reset_index()\n",
    "grouped_tweets_test = grouped_tweets_test.drop(columns=['person_id']) \n",
    "grouped_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      proud rolltid victorywednesday thankyoualabama...\n",
       "1      rt lsufbrecruit nflsu week top perform rt lsuf...\n",
       "2      rememb one time trump profession sport team in...\n",
       "3      doston miliy mere nay jodidaar se br humn kasa...\n",
       "4      rt shinnox everi mk champion breakfast choic n...\n",
       "                             ...                        \n",
       "515    ani row interest come hong kong play month con...\n",
       "516    nojokemok yes sr let get great wish could got ...\n",
       "517    hildaesq emorrisonsmith risesandiego wish coul...\n",
       "518    divorc renew season hbo new showrunn varieti a...\n",
       "519    rt durstjarmarqui truli bless onli part texasf...\n",
       "Name: tweet, Length: 520, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = grouped_tweets_test['tweet'] #cleaned_tweets_username / cleaned_tweets\n",
    "X_test = X_test.apply(lambda row : ' '.join(row)) \n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train classifierers and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(y_test, predictions):\n",
    "    print(\"Confusin Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(\"Accuracy Score:\")\n",
    "    print(metrics.accuracy_score(y_test,predictions))\n",
    "\n",
    "def train_data_naive_bayes(categorie):\n",
    "    print(\"naive_bayes\")\n",
    "    \n",
    "    y_train = labels_train[categorie]\n",
    "    y_test = labels_test[categorie]\n",
    "    \n",
    "    text_clf_nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "    \n",
    "    text_clf_nb.fit(X_train, y_train) \n",
    "    \n",
    "    predictions = text_clf_nb.predict(X_test)\n",
    "   \n",
    "    show_res(y_test, predictions)\n",
    "\n",
    "\n",
    "def train_data_linear_svc(categorie):\n",
    "    print(\"linear_svc\")\n",
    "    \n",
    "    y_train = labels_train[categorie]\n",
    "    y_test = labels_test[categorie]\n",
    "    \n",
    "    text_clf_lsvc = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', LinearSVC()),\n",
    "              ])\n",
    "    \n",
    "    text_clf_lsvc.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = text_clf_lsvc.predict(X_test)\n",
    "    show_res(y_test, predictions)\n",
    "\n",
    "\n",
    "def train_data_SGDClassifier(categorie):\n",
    "    print(\"SGDClassifier\")\n",
    "        \n",
    "    y_train = labels_train[categorie]\n",
    "    y_test = labels_test[categorie]\n",
    "    \n",
    "    text_clf_lsvc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier()), \n",
    "               ])\n",
    "    # loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None\n",
    "    \n",
    "    text_clf_lsvc.fit(X_train, y_train)\n",
    "\n",
    "    predictions = text_clf_lsvc.predict(X_test)\n",
    "    show_res(y_test, predictions) \n",
    "\n",
    "def train_data_LogistigRegression(categorie):\n",
    "    print(\"LogistigRegression\")\n",
    "    \n",
    "    y_train = labels_train[categorie]\n",
    "    y_test = labels_test[categorie]\n",
    "    \n",
    "    text_clf_lsvc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)),\n",
    "               ])\n",
    "    \n",
    "    text_clf_lsvc.fit(X_train, y_train)\n",
    "\n",
    "    predictions = text_clf_lsvc.predict(X_test)\n",
    "    show_res(y_test, predictions) \n",
    "\n",
    "def train_data_DecisionTreeClassifier(categorie):\n",
    "    print(\"DecisionTreeClassifier\")\n",
    "\n",
    "    y_train = labels_train[categorie]\n",
    "    y_test = labels_test[categorie]\n",
    "    \n",
    "    clf_generation = DecisionTreeClassifier()\n",
    "    clf_generation.fit(X_train, y_train)\n",
    "\n",
    "    predictions = text_clf_lsvc.predict(X_test)\n",
    "    show_res(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "Confusin Matrix:\n",
      "[[  0 100]\n",
      " [  0 420]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.00      0.00      0.00       100\n",
      "        male       0.81      1.00      0.89       420\n",
      "\n",
      "    accuracy                           0.81       520\n",
      "   macro avg       0.40      0.50      0.45       520\n",
      "weighted avg       0.65      0.81      0.72       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.8076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\NLP_2020\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_data_naive_bayes('gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier\n",
      "Confusin Matrix:\n",
      "[[  6  94]\n",
      " [  8 412]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.43      0.06      0.11       100\n",
      "        male       0.81      0.98      0.89       420\n",
      "\n",
      "    accuracy                           0.80       520\n",
      "   macro avg       0.62      0.52      0.50       520\n",
      "weighted avg       0.74      0.80      0.74       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.8038461538461539\n"
     ]
    }
   ],
   "source": [
    "train_data_SGDClassifier('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_svc\n",
      "Confusin Matrix:\n",
      "[[  6  94]\n",
      " [  4 416]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.60      0.06      0.11       100\n",
      "        male       0.82      0.99      0.89       420\n",
      "\n",
      "    accuracy                           0.81       520\n",
      "   macro avg       0.71      0.53      0.50       520\n",
      "weighted avg       0.77      0.81      0.74       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.8115384615384615\n"
     ]
    }
   ],
   "source": [
    "train_data_linear_svc('gender')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogistigRegression\n",
      "[LibLinear]Confusin Matrix:\n",
      "[[  4  96]\n",
      " [  1 419]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.80      0.04      0.08       100\n",
      "        male       0.81      1.00      0.90       420\n",
      "\n",
      "    accuracy                           0.81       520\n",
      "   macro avg       0.81      0.52      0.49       520\n",
      "weighted avg       0.81      0.81      0.74       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.8134615384615385\n"
     ]
    }
   ],
   "source": [
    "train_data_LogistigRegression('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "Confusin Matrix:\n",
      "[[  0   0   0  78   0]\n",
      " [  0   0   0 108   0]\n",
      " [  0   0   0  31   0]\n",
      " [  0   0   0 290   0]\n",
      " [  0   0   0  13   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Boomers       0.00      0.00      0.00        78\n",
      "Generation X       0.00      0.00      0.00       108\n",
      "Generation Z       0.00      0.00      0.00        31\n",
      " Millennials       0.56      1.00      0.72       290\n",
      "      Silent       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.56       520\n",
      "   macro avg       0.11      0.20      0.14       520\n",
      "weighted avg       0.31      0.56      0.40       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.5576923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\NLP_2020\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_data_naive_bayes('generation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier\n",
      "Confusin Matrix:\n",
      "[[  4   2   1  71   0]\n",
      " [  6   5   1  96   0]\n",
      " [  0   2   0  29   0]\n",
      " [ 11  21   3 255   0]\n",
      " [  1   2   0  10   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Boomers       0.18      0.05      0.08        78\n",
      "Generation X       0.16      0.05      0.07       108\n",
      "Generation Z       0.00      0.00      0.00        31\n",
      " Millennials       0.55      0.88      0.68       290\n",
      "      Silent       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.51       520\n",
      "   macro avg       0.18      0.20      0.17       520\n",
      "weighted avg       0.37      0.51      0.41       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.5076923076923077\n"
     ]
    }
   ],
   "source": [
    "train_data_SGDClassifier('generation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_svc\n",
      "Confusin Matrix:\n",
      "[[  3   1   0  74   0]\n",
      " [  4   3   1 100   0]\n",
      " [  0   2   0  29   0]\n",
      " [  7  15   1 267   0]\n",
      " [  1   1   0  11   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Boomers       0.20      0.04      0.06        78\n",
      "Generation X       0.14      0.03      0.05       108\n",
      "Generation Z       0.00      0.00      0.00        31\n",
      " Millennials       0.56      0.92      0.69       290\n",
      "      Silent       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.53       520\n",
      "   macro avg       0.18      0.20      0.16       520\n",
      "weighted avg       0.37      0.53      0.41       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.525\n"
     ]
    }
   ],
   "source": [
    "train_data_linear_svc('generation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogistigRegression\n",
      "[LibLinear]Confusin Matrix:\n",
      "[[  2   1   0  75   0]\n",
      " [  1   0   0 107   0]\n",
      " [  0   0   0  31   0]\n",
      " [  2   7   0 281   0]\n",
      " [  0   0   0  13   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Boomers       0.40      0.03      0.05        78\n",
      "Generation X       0.00      0.00      0.00       108\n",
      "Generation Z       0.00      0.00      0.00        31\n",
      " Millennials       0.55      0.97      0.71       290\n",
      "      Silent       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.54       520\n",
      "   macro avg       0.19      0.20      0.15       520\n",
      "weighted avg       0.37      0.54      0.40       520\n",
      "\n",
      "Accuracy Score:\n",
      "0.5442307692307692\n"
     ]
    }
   ],
   "source": [
    "train_data_LogistigRegression('generation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_naive_bayes('occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_SGDClassifier('occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_linear_svc('occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_LogistigRegression('occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
